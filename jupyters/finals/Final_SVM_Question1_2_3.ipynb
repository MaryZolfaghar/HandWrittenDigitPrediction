{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, GridSearchCV,\\\n",
    "                                    StratifiedKFold, KFold,\\\n",
    "                                    StratifiedShuffleSplit, RepeatedStratifiedKFold, \\\n",
    "                                    cross_val_score, cross_validate\n",
    "                                    \n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from mne.decoding import cross_val_multiscore, LinearModel, \\\n",
    "                         GeneralizingEstimator, Scaler, Vectorizer\n",
    "\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3747, 8)\n",
      "(3747,)\n"
     ]
    }
   ],
   "source": [
    "class arguments():\n",
    "    def __init__(self):\n",
    "        self.DATAPATH = '../data/'\n",
    "\n",
    "args = arguments()\n",
    "\n",
    "train = pd.read_csv(args.DATAPATH + 'studentspen-train.csv')\n",
    "test = pd.read_csv(args.DATAPATH + 'studentsdigits-test.csv')\n",
    "\n",
    "X = train[['x3', 'y3', 'x4', 'y4', 'x5', 'y5', 'x6', 'y6']].values\n",
    "Y = train['Digit'].values\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state=45\n",
    "max_iter=1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_split for linear = 10 and for polynomial = 6\n",
    "n_split_linear=10\n",
    "n_split_poly=6\n",
    "\n",
    "cv1 = StratifiedShuffleSplit(n_splits=n_split_linear, random_state=rand_state) \n",
    "cv2 = StratifiedShuffleSplit(n_splits=n_split_poly, random_state=rand_state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 and 2\n",
    "\n",
    "Question 1): Train a  linear multi-class classification SVM with no kernel.  Specify i) Your mapping function and ii) Your loss function  (20 points)\n",
    "\n",
    "Question 2) Describe a method to estimate your performance using an empirical method. Compare this estimate with a well known theoretical bound. Explain why/if there is a difference. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finalized classifiers\n",
    "## Applying finalized classifier on the actual test data and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3747, 8)\n",
      "(3747,)\n",
      "(3747, 8)\n"
     ]
    }
   ],
   "source": [
    "class arguments():\n",
    "    def __init__(self):\n",
    "        self.DATAPATH = '../data/'\n",
    "\n",
    "args = arguments()\n",
    "\n",
    "train = pd.read_csv(args.DATAPATH + 'studentspen-train.csv')\n",
    "test = pd.read_csv(args.DATAPATH + 'studentsdigits-test.csv')\n",
    "\n",
    "X_train = train[['x3', 'y3', 'x4', 'y4', 'x5', 'y5', 'x6', 'y6']].values\n",
    "y_train = train['Digit'].values\n",
    "\n",
    "X_test = test[['x3', 'y3', 'x4', 'y4', 'x5', 'y5', 'x6', 'y6']].values\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one vs rest\n",
      "[0.744      0.744      0.736      0.72       0.70933333 0.736\n",
      " 0.73866667 0.712      0.736      0.73866667]\n",
      "0.7314666666666667\n",
      "one vs one\n",
      "[0.86133333 0.89333333 0.86933333 0.872      0.86666667 0.89066667\n",
      " 0.872      0.848      0.87733333 0.91466667]\n",
      "0.8765333333333333\n",
      "one vs rest\n",
      "[0.71733333 0.70666667 0.70133333 0.71733333 0.69066667 0.67466667\n",
      " 0.69066667 0.68       0.704      0.70133333]\n",
      "0.6984\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------------\n",
    "# Linear SVC\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "svm_final_1 = make_pipeline(StandardScaler(), LinearSVC(loss='squared_hinge', random_state=rand_state,\\\n",
    "                                                        C=8, max_iter=max_iter, class_weight='balanced'))\n",
    "\n",
    "svm_final_1_scores  = cross_val_score(svm_final_1, X, Y, cv=cv1, n_jobs=1)\n",
    "print('one vs rest')\n",
    "print(svm_final_1_scores)\n",
    "print(np.mean(svm_final_1_scores))\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "# SVC with one vs rest wrapper\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "svm_final_2 = make_pipeline(StandardScaler(), SVC(kernel='linear', random_state=rand_state, \\\n",
    "                                                  C=8, max_iter=max_iter, class_weight='balanced'))\n",
    "svm_final_2_scores  = cross_val_score(svm_final_2, X, Y, cv=cv1, n_jobs=1)\n",
    "print('one vs one')\n",
    "print(svm_final_2_scores)\n",
    "print(np.mean(svm_final_2_scores))\n",
    "\n",
    "#----------------------------------\n",
    "svm_final_3 = OneVsRestClassifier(svm_final_2)\n",
    "svm_final_3_scores     = cross_val_score(svm_final_3, X, Y, cv=cv1, n_jobs=1)\n",
    "print('one vs rest')\n",
    "print(svm_final_3_scores)\n",
    "print(np.mean(svm_final_3_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 PAC Bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perf(x1, x2):\n",
    "    nn = x1.shape[0]\n",
    "    scores = np.zeros([nn, 1])\n",
    "    for ii in range(nn):\n",
    "        if x1[ii]==x2[ii]:\n",
    "            scores[ii] = 1\n",
    "        else:\n",
    "            scores[ii] = 0\n",
    "    corr = np.sum(scores, axis=0)\n",
    "    perf = (corr / nn) \n",
    "    return corr, perf\n",
    "\n",
    "def calc_err(x1, x2):\n",
    "    nn = x1.shape[0]\n",
    "    scores = np.zeros([nn, 1])\n",
    "    for ii in range(nn):\n",
    "        if x1[ii]!=x2[ii]:\n",
    "            scores[ii] = 1\n",
    "        else:\n",
    "            scores[ii] = 0\n",
    "    incorr = np.sum(scores, axis=0)\n",
    "    incorr_prcng = (incorr / nn)\n",
    "    return incorr, incorr_prcng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (3372,)\n",
      "test/validation shape (375,)\n",
      "train shape (3372,)\n",
      "test/validation shape (375,)\n",
      "train shape (3372,)\n",
      "test/validation shape (375,)\n",
      "train shape (3372,)\n",
      "test/validation shape (375,)\n",
      "train shape (3372,)\n",
      "test/validation shape (375,)\n",
      "train shape (3372,)\n",
      "test/validation shape (375,)\n",
      "train shape (3372,)\n",
      "test/validation shape (375,)\n",
      "train shape (3372,)\n",
      "test/validation shape (375,)\n",
      "train shape (3372,)\n",
      "test/validation shape (375,)\n",
      "train shape (3372,)\n",
      "test/validation shape (375,)\n",
      "\n",
      " one vs rest\n",
      "[905.] [0.26838671]\n",
      "[98.] [0.26133333]\n",
      "\n",
      "\n",
      "[2467.] [0.73161329]\n",
      "[277.] [0.73866667]\n",
      "\n",
      "\n",
      "train shape (3372,)\n",
      "test/validation shape (375,)\n",
      "\n",
      " one vs one\n",
      "[423.] [0.12544484]\n",
      "[32.] [0.08533333]\n",
      "\n",
      "\n",
      "[2949.] [0.87455516]\n",
      "[343.] [0.91466667]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------------\n",
    "# One vs Rest\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "for trg_train_index, trg_test_index in cv1.split(X_train, y_train):\n",
    "    print('train shape', trg_train_index.shape)\n",
    "    print('test/validation shape', trg_test_index.shape)\n",
    "\n",
    "svm_final_1.fit(X_train[trg_train_index], y_train[trg_train_index])\n",
    "\n",
    "y_pred_train = svm_final_1.predict(X_train[trg_train_index])\n",
    "y_pred_test = svm_final_1.predict(X_train[trg_test_index])\n",
    "\n",
    "incorr1, incorr_prcng1 = calc_err(y_train[trg_train_index], y_pred_train)\n",
    "incorr2, incorr_prcng2 = calc_err(y_train[trg_test_index], y_pred_test)\n",
    "print('\\n one vs rest')\n",
    "print(incorr1, incorr_prcng1)\n",
    "print(incorr2, incorr_prcng2)\n",
    "print('\\n')\n",
    "\n",
    "corr1, perf1 = calc_perf(y_train[trg_train_index], y_pred_train)\n",
    "corr2, perf2 = calc_perf(y_train[trg_test_index], y_pred_test)\n",
    "print(corr1, perf1)\n",
    "print(corr2, perf2)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "# One vs One\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "for trg_train_index, trg_test_index in cv1.split(X_train, y_train):\n",
    "    pass\n",
    "\n",
    "print('train shape', trg_train_index.shape)\n",
    "print('test/validation shape', trg_test_index.shape)\n",
    "\n",
    "svm_final_2.fit(X_train[trg_train_index], y_train[trg_train_index])\n",
    "\n",
    "y_pred_train = svm_final_2.predict(X_train[trg_train_index])\n",
    "y_pred_test = svm_final_2.predict(X_train[trg_test_index])\n",
    "\n",
    "incorr1, incorr_prcng1 = calc_err(y_train[trg_train_index], y_pred_train)\n",
    "incorr2, incorr_prcng2 = calc_err(y_train[trg_test_index], y_pred_test)\n",
    "print('\\n one vs one')\n",
    "print(incorr1, incorr_prcng1)\n",
    "print(incorr2, incorr_prcng2)\n",
    "print('\\n')\n",
    "\n",
    "corr1, perf1 = calc_perf(y_train[trg_train_index], y_pred_train)\n",
    "corr2, perf2 = calc_perf(y_train[trg_test_index], y_pred_test)\n",
    "print(corr1, perf1)\n",
    "print(corr2, perf2)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs Rest\n",
    "PAC#1 = 1/3372(905+17.52-18.36)=0.268 -> 73.2%\n",
    "### One vs One\n",
    "PAC#1 = 1/3372(423+17.52-18.36)=0.125  -> ~87.5 %\n",
    "\n",
    "PAC#2 for both= max(0.00007, 59.91) = 59.9 -> 40.08 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Question 3) Submit your predictions on this test set, one prediction per line in the order given studentsdigits-test.csvPreview the document (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------------\n",
    "# One vs Rest\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "svm_final_1.fit(X_train, y_train)\n",
    "y_pred = svm_final_1.predict(X_test)\n",
    "\n",
    "\n",
    "SAVE_RESULT_ROOT = '../results/'\n",
    "fn_str = SAVE_RESULT_ROOT + 'MaryZolfaghar_preds_Q3_OneVsRest.txt'\n",
    "a_file = open(fn_str, \"w\")\n",
    "\n",
    "for row in y_pred:\n",
    "    res = str(row)\n",
    "    a_file.write(str(int(float(res)))+\"\\n\")\n",
    "a_file.close()\n",
    "print('done')\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "# One Vs One\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "svm_final_2.fit(X_train, y_train)\n",
    "y_pred_ovo = svm_final_2.predict(X_test)\n",
    "\n",
    "\n",
    "SAVE_RESULT_ROOT = '../results/'\n",
    "fn_str = SAVE_RESULT_ROOT + 'MaryZolfaghar_preds_Q3_OneVsOne.txt'\n",
    "a_file = open(fn_str, \"w\")\n",
    "\n",
    "for row in y_pred_ovo:\n",
    "    res = str(row)\n",
    "    a_file.write(str(int(float(res)))+\"\\n\")\n",
    "a_file.close()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "1. It might be easier to use GridSearch, but faster to do it separately to have a general idea\n",
    "1.1. So far I got C=8 for kernel ='linear', and n_splits=10 gave me the best result, gamma was not affecting the results\n",
    "1.2. I tried to double check that with \n",
    "2. It might be a better cross validation to do a nested and non-nested cross validation\n",
    "3. For being able to plot I might need to use cross predict: https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_predict.html#sphx-glr-auto-examples-model-selection-plot-cv-predict-py\n",
    "\n",
    "4. SVC was way better than linearSVC\n",
    "5. For transfer learning i might be able to use cross predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearnigEEG",
   "language": "python",
   "name": "deeplearnigeeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
